import { useNavigate } from "react-router-dom";
import React, { useState, useEffect } from "react";
import axios from "axios";
import { useDebounce } from "../Common/hooks/useDebounce";
import styles from "./StudentDiary.module.css";
import SpeechRecognition, {
  useSpeechRecognition,
} from "react-speech-recognition";
import { Configuration, OpenAIApi } from "openai";
import TTSsentence from "../Common/TTSsentence";

export default function StudentTalking() {
  // [ë…¹ìŒ]
  const { transcript, listening } = useSpeechRecognition();
  const debounceTerm = useDebounce(transcript, 2000);

  // debounceTermë‚´ìš©ì„ allConversationsì— ì €ì¥í• ê±°ì•¼.
  // 3ë²ˆ ì•ˆëìœ¼ë©´ GPTì— ë³´ë‚´ì„œ ì§ˆë¬¸ì„ ë§Œë“¤ê±°ì•¼.
  useEffect(() => {
    if (debounceTerm) {
      setAllConversations((prev) => [
        ...prev,
        { type: "user", content: debounceTerm },
      ]);
      console.log(allConversations);
      if (conversationCount < 3) {
        generateText(debounceTerm);
      }
    }
  }, [debounceTerm]);

  // [TTS]
  const [msg, setMsg] = useState(null);
  const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

  // TTS ìƒì„±í•¨ìˆ˜
  const ttsMaker = async (msg, timer) => {
    return new Promise((resolve) => {
      setTimeout(() => {
        setMsg(msg);
        resolve();
      }, timer);
    });
  };

  // TTS ì²« ì§ˆë¬¸
  useEffect(() => {
    async function makeRequest() {
      let text = `ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?`;
      ttsMaker(text, 0);
      await delay(text.length * 250);
      SpeechRecognition.startListening();
    }
    makeRequest();
  }, []);

  // [GPT]
  const [isGenerating, setIsGenerating] = useState(false);
  const [generatedText, setGeneratedText] = useState("");
  const [allConversations, setAllConversations] = useState([]);
  const [conversationCount, setConversationCount] = useState(0);
  const [generatedDiary, setGeneratedDiary] = useState(""); //ì‚­ì œì˜ˆì •

  // GPTì— ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë³´ë‚´ì„œ ì§ˆë¬¸ì„ ë°›ì•„ì™€, generatedMessageì— ì €ì¥í•´
  const generateText = async (message) => {
    if (!isGenerating) {
      setIsGenerating(true);
      try {
        const apiKey = "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";
        const configuration = new Configuration({
          apiKey: apiKey,
        });
        const openai = new OpenAIApi(configuration);

        const response = await openai.createChatCompletion({
          model: "gpt-3.5-turbo",
          messages: [
            {
              role: "system",
              content:
                "You are a helpful assistant. Whenever the user shares a statement or sentiment, ask a relevant and engaging question in response, using Korean honorifics (ì¡´ëŒ“ë§).",
            },
            {
              role: "user",
              content: `${message}`,
            },
          ],
        });

        const generatedMessage = response.data.choices[0].message.content;
        setGeneratedText(generatedMessage);
        console.log(generatedMessage);
      } catch (error) {
        console.error("Error:", error);
      } finally {
        setIsGenerating(false);
      }
    }
  };

  // GPTì—ì„œ ì§ˆë¬¸ ë°›ìœ¼ë©´ -> ë°°ì—´ì— ì¶”ê°€í•˜ê³ , TTSë¡œ ì½ê³ , ë…¹ìŒ ì‹œì‘ (ë‘ë²ˆì§¸ ì§ˆë¬¸ë¶€í„°)
  useEffect(() => {
    if (generatedText) {
      setAllConversations((prev) => [
        ...prev,
        { type: "response", content: generatedText },
      ]);
      setConversationCount((prev) => prev + 1); // GPT-3 ì‘ë‹µ í›„ ì¹´ìš´íŠ¸ ì¦ê°€
      async function ttsAndListen() {
        await ttsMaker(generatedText, 0);
        await delay(generatedText.length * 250);
        if (conversationCount < 3) {
          // ìˆ˜ì •: ì‘ë‹µ 2ë²ˆ í›„ì—ë§Œ ìŒì„± ì…ë ¥ ëŒ€ê¸°
          SpeechRecognition.startListening();
        }
      }
      ttsAndListen();
    }
  }, [generatedText]);

  console.log(allConversations);

  // í˜ì´ì§€ ì´ë™, ìˆ˜ì •ì˜ˆì •
  const navigate = useNavigate();

  useEffect(() => {
    async function checkAndNavigate() {
      if (conversationCount >= 3) {
        // 1. allConversations ë°°ì—´ì—ì„œ typeì´ 'user'ì¸ ê°ì²´ë“¤ë§Œ í•„í„°ë§
        const userConversations = allConversations.filter(
          (convo) => convo.type === "user"
        );

        // 2. ì´ë“¤ì˜ contentë§Œ ë”°ë¡œ ëª¨ì•„ ë°°ì—´ë¡œ ë§Œë“¦
        const userContents = userConversations.map((convo) => convo.content);

        // 3. ë§Œë“  ë°°ì—´ì„ diary í˜ì´ì§€ë¡œ ì „ë‹¬
        navigate("/diary", { state: { userConversations: userContents } });
      }
    }

    checkAndNavigate();
  }, [conversationCount]);

  return (
    <div className={styles.main}>
      <div className={styles.square}>
        <div className={styles.theme}>
          <div className={styles.text}></div>
          <div className={styles.microphone}>
            <h1>ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?</h1>
            <p className={styles.volume}>{listening ? "ğŸ”Š" : "ğŸ”‡"}</p>

            {allConversations.map((conversation, index) => (
              <div
                key={index}
                className={
                  conversation.type === "user"
                    ? styles.userMessage
                    : styles.generatedMessage
                }
              >
                {conversation.content}
              </div>
            ))}

            {msg && <TTSsentence message={msg} />}
            <div></div>
          </div>
        </div>
      </div>
    </div>
  );
}
