import React, { useState, useEffect } from "react";
import { useNavigate } from "react-router-dom";
import styles from "./StudentRecordWord.module.css";
import SpeechRecognition, { useSpeechRecognition } from "react-speech-recognition";
import { useDispatch, useSelector } from "react-redux";
import { Configuration, OpenAIApi } from "openai";

import TTSsentence from "../Common/TTSsentence";

export default function StudentRecordWord() {
  // DBì— ì €ì¥ëœ ë‹¨ì–´ ê°€ì ¸ì˜¤ê¸°
  const wordsList = useSelector((state) => state.themeState.wordsList) || [];
  const wordIndex = useSelector((state) => state.wordIndexState.wordIndex);

  // ìŒì„±ì¸ì‹ ê´€ë ¨
  const { transcript, listening } = useSpeechRecognition();

  // TTS ê´€ë ¨
  const [count, setCount] = useState(0);
  const [msg, setMsg] = useState(null);

  const ttsMaker = async (msg, timer) => {
    return new Promise((resolve) => {
      setTimeout(() => {
        setMsg(msg);
        resolve();
      }, timer);
    });
  };

  const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

  const helpGpt = async () => {
    const apiKey = "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";

    const configuration = new Configuration({
      apiKey: apiKey,
    });
    const openai = new OpenAIApi(configuration);

    const response = await openai.createChatCompletion({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "70ëŒ€ ì–´ë¥´ì‹ ë“¤ì—ê²Œ í•œê¸€ì„ ê°€ë¥´ì³ ë“œë¦´êº¼ì•¼!." },
        {
          role: "user",
          content: `ì •ë‹µì¸ "${wordsList[wordIndex].word}"ì— ëŒ€í•´ "${transcript}"ê°€ í‹€ë¦° ë¶€ë¶„ì„ ì§§ê²Œ í•œì¤„ë¡œ ì„¤ëª…í•´ì¤˜`,
        },
      ],
    });

    let text = response.data.choices[0].message.content;
    ttsMaker(text, 0);
    await delay(text.length * 250);
  };

  useEffect(() => {
    async function makeRequest(data) {
      await delay(1000);

      ttsMaker(data, 0);
      await delay(data.length * 250);
      ttsMaker("", 0);

      SpeechRecognition.startListening();
      await delay(4000);
      SpeechRecognition.stopListening();

      setCount(count + 1);
    }

    async function work(data) {
      if (data === wordsList[wordIndex].word) {
        navigate("/good-feedback", { state: { course: "reading" } });
      } else {
        if (count == 1) {
          await helpGpt();
        }
        setCount(count + 1);
      }
    }

    if (count == 0) {
      makeRequest("ë‹¨ì–´ë¥¼ ì½ì–´ì£¼ì„¸ìš”!!");
      console.log(transcript);
    } else if (count == 1) {
      work(transcript);
      // console.log(transcript);
    } else if (count == 2) {
      makeRequest("ë‹¤ì‹œ ë‹¨ì–´ë¥¼ ì½ì–´ì£¼ì„¸ìš”!!");
    } else if (count == 3) {
      work(transcript);
    } else if (count == 4) {
      makeRequest(`ë‹¨ì–´ë¥¼ ê°™ì´ ì½ì–´ìš”!!! ${wordsList[wordIndex].word} `);
    } else {
      navigate("/good-feedback", { state: { course: "reading" } });
    }
  }, [count]);

  const navigate = useNavigate();

  return (
    <div className={styles.main}>
      <div className={styles.square}>
        <div className={styles.theme}>
          {/* <img
            className={styles.wordimg}
            src={wordsList.length > 0 && wordsList[wordIndex].wordImageUrl}
            alt=""
          /> */}

          <div className={styles.text}>
            <h1 className={styles.situationText}>
              {wordsList.length > 0 && wordsList[wordIndex].word}
            </h1>
          </div>
          <div>
            {/* {wordsList[wordIndex].word && (
              <TTS repeat={repeatValue} message={wordsList[wordIndex].word} />
            )} */}
            {/* && ì•ì— ì¡°ê±´ì„ Reduxì—ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ê±¸ë¡œ í•´ë‘¬ì•¼ ë¶ˆëŸ¬ì˜¤ê¸°ì „ì— TTS ì‹¤í–‰ì„ ì•ˆí•¨ */}
          </div>
          <div className={styles.microphone}>
            <p className={styles.volume}>{listening ? "ğŸ”Š" : "ğŸ”‡"}</p>
            <p>{transcript}</p>
            {msg && <TTSsentence message={msg} />}
          </div>
        </div>
      </div>
    </div>
  );
}
